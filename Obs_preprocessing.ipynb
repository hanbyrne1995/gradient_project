{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observational data preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to work out the preprocessing needed for observational datasets. Ultimately plan to create a class for this pre processing.  \n",
    "\n",
    "Datasets included: HadISST, COBE, COBE2, Kaplan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import pooch\n",
    "from datetime import datetime\n",
    "\n",
    "from GradientProjectFunctions import lat_lon_res_Eq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hadley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "odie = pooch.create(\n",
    "    path = pooch.os_cache('HadISST'),\n",
    "    base_url = 'https://www.metoffice.gov.uk/hadobs/hadisst/data/',\n",
    "    registry = {\n",
    "        'HadISST_sst.nc.gz': 'sha256:b03d7c0adcdc29b1687ee2bb22c322a6019547aee3339f29af0a6dc505e7477f'\n",
    "    },\n",
    ")\n",
    "\n",
    "file_path = odie.fetch('HadISST_sst.nc.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsHad = xr.open_dataset(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COBE2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'http://psl.noaa.gov/thredds/dodsC/Datasets/COBE2/sst.mon.mean.nc'\n",
    "dsCOBE2 = xr.open_dataset(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'http://psl.noaa.gov/thredds/dodsC/Datasets/COBE/sst.mon.mean.nc'\n",
    "dsCOBE = xr.open_dataset(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kaplan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'http://psl.noaa.gov/thredds/dodsC/Datasets/kaplan_sst/sst.mean.anom.nc'\n",
    "dsKaplan = xr.open_dataset(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning coordinate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsObs = dsKaplan\n",
    "\n",
    "try:\n",
    "    if 'lat' not in dsObs.dims:\n",
    "        if 'y' in dsObs.dims:\n",
    "            dsObs = dsObs.rename({'y': 'lat'})\n",
    "        elif 'latitude' in dsObs.dims:\n",
    "            dsObs = dsObs.rename({'latitude': 'lat'})\n",
    "\n",
    "    if 'lon' not in dsObs.dims:\n",
    "        if 'x' in dsObs.dims:\n",
    "            dsObs = dsObs.rename({'x': 'lon'})\n",
    "        elif 'longitude' in dsObs.dims:\n",
    "            dsObs = dsObs.rename({'longitude': 'lon'})\n",
    "\n",
    "    # print('Successful coordinate cleaning')\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    print(f'Error checking and correcting coordinates: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rolling coordinates (lat and lon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want coords to go 0-360 and -90 - 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first check if they are correct already\n",
    "\n",
    "# longitude\n",
    "if not (np.floor(dsObs.lon[0]) <= 5) & (np.ceil(dsObs.lon[-1]) >= 350):\n",
    "    dsObs = dsObs.assign_coords(lon = ((360 + (dsObs.lon % 360)) % 360))\n",
    "    dsObs = dsObs.roll(lon = int(len(dsObs.lon) / 2), roll_coords = True)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# latitude\n",
    "if not (np.floor(dsObs.lat[0]) == -90) & (np.ceil(dsObs.lat[-1]) == 90):\n",
    "    dsObs = dsObs.sortby('lat')\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making time the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "convertedTime = pd.to_datetime(dsObs.time.values.astype(str))\n",
    "dsObs['time'] = ('time', convertedTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude: Mean: 5.00 and SD: 0.000\n",
      "Longitude: Mean: 5.00 and SD: 0.000\n"
     ]
    }
   ],
   "source": [
    "lat_lon_res_Eq(dsObs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the time span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset spans from 1856-01 to 2023-01\n"
     ]
    }
   ],
   "source": [
    "dateFirst = np.datetime_as_string(dsObs.time[0].values, unit = 'M')\n",
    "dateLast = np.datetime_as_string(dsObs.time[-1].values, unit = 'M')\n",
    "\n",
    "print(f'Dataset spans from {dateFirst} to {dateLast}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a class for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepObsData:\n",
    "    def __init__(self, dsObs):\n",
    "        '''\n",
    "        Takes the input of an observational dataset and cleans the data as follows:\n",
    "        - standardises coordinate names to lat and lon\n",
    "        - rolls coordinates so that lon goes 0-360 and lat goes -90 - 90\n",
    "        - corrects the format of the time to be standard\n",
    "        - checks the resolution of the dataset around the 10Â° band about the equator\n",
    "        - outputs the length of the dataset\n",
    "        \n",
    "        :param: dsObs: observational dataset\n",
    "        '''\n",
    "        \n",
    "        self.dsObs = dsObs\n",
    "        self.dsOut = self.ExecAllSteps()\n",
    "        \n",
    "    def CleanCoords(self):\n",
    "        \n",
    "        try:\n",
    "            if 'lat' not in self.dsObs.dims:\n",
    "                if 'y' in self.dsObs.dims:\n",
    "                    self.dsOut = self.dsObs.rename({'y': 'lat'})\n",
    "                elif 'latitude' in self.dsObs.dims:\n",
    "                    self.dsOut = self.dsObs.rename({'latitude': 'lat'})\n",
    "\n",
    "            if 'lon' not in self.dsOut.dims:\n",
    "                if 'x' in self.dsOut.dims:\n",
    "                    self.dsOut = self.dsOut.rename({'x': 'lon'})\n",
    "                elif 'longitude' in self.dsOut.dims:\n",
    "                    self.dsOut = self.dsOut.rename({'longitude': 'lon'})\n",
    "            \n",
    "            return self.dsOut\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(f'Error checking and correcting coordinate names: {e}')\n",
    "    \n",
    "    def RollCoords(self):\n",
    "        \n",
    "        try:\n",
    "            # longitude\n",
    "            if not (np.floor(self.dsOut.lon[0]) <= 5) & (np.ceil(self.dsOut.lon[-1]) >= 350):\n",
    "                self.dsOut = self.dsOut.assign_coords(lon = ((360 + (self.dsOut.lon % 360)) % 360))\n",
    "                self.dsOut = self.dsOut.roll(lon = int(len(self.dsOut.lon) / 2), roll_coords = True)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            # latitude\n",
    "            if not (np.floor(self.dsOut.lat[0]) == -90) & (np.ceil(self.dsOut.lat[-1]) == 90):\n",
    "                self.dsOut = self.dsOut.sortby('lat')\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            return self.dsOut\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f'Error rolling coordinates: {e}')\n",
    "        \n",
    "    def CleanTime(self):\n",
    "        \n",
    "        try:\n",
    "            convertedTime = pd.to_datetime(self.dsOut.time.values.astype(str))\n",
    "            self.dsOut['time'] = ('time', convertedTime)\n",
    "            \n",
    "            return self.dsOut\n",
    "        \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f'Error cleaning the time coordinate: {e}')\n",
    "    \n",
    "    def CheckingResolution(self):\n",
    "        \n",
    "        try:\n",
    "            lat_lon_res_Eq(self.dsOut)\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f'Error checking resolution: {e}')\n",
    "            \n",
    "    def CheckingTime(self):\n",
    "        \n",
    "        try:\n",
    "            dateFirst = np.datetime_as_string(self.dsOut.time[0].values, unit = 'M')\n",
    "            dateLast = np.datetime_as_string(self.dsOut.time[-1].values, unit = 'M')\n",
    "\n",
    "            print(f'Dataset spans from {dateFirst} to {dateLast}')\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f'Error checking time: {e}')\n",
    "            \n",
    "    def ExecAllSteps(self):\n",
    "        self.CleanCoords()\n",
    "        self.RollCoords()\n",
    "        self.CleanTime()\n",
    "        self.CheckingResolution()\n",
    "        self.CheckingTime()\n",
    "        return self.dsOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latitude: Mean: 1.00 and SD: 0.000\n",
      "Longitude: Mean: 1.00 and SD: 0.000\n",
      "Dataset spans from 1870-01 to 2024-02\n"
     ]
    }
   ],
   "source": [
    "test = PrepObsData(dsHad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/hbyrne/Research/Tools')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils_Functions_HB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python hb_1129",
   "language": "python",
   "name": "hb_1129"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
